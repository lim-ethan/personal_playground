# Apache Kafka 학습 로드맵

## 1단계: Kafka 기본 개념 이해 (입문)
- Kafka의 기본 아키텍처 이해 (Broker, Topic, Partition, Producer, Consumer, Zookeeper/KRaft)
- 메시지의 생산과 소비 흐름 익히기
- Partition, Offset, Consumer Group 개념 명확히 정리
- `acks` 옵션과 메시지 내결함성 기본 개념 이해
- Kafka 공식 문서, 유튜브 기본 강의, 블로그 글 참고

---

## 2단계: Kafka 실습 및 기본 명령어 활용
- 로컬 환경에 Kafka 설치 및 실행 (단일 브로커 구성부터 시작)
- 토픽 생성, 메시지 produce/consume 명령어 실습
- Producer, Consumer API로 간단한 프로그램 작성해보기 (Java 또는 Python)
- `acks`, `replication.factor`, `retention.ms` 등 주요 설정 파라미터 실습으로 이해
- Consumer Group 동작 원리 실습 (여러 Consumer가 메시지를 나눠 읽는 과정)

---

## 3단계: Kafka 운영 및 내결함성 이해 (중급)
- Kafka 클러스터 구성 및 Broker 확장 (멀티 브로커 클러스터 구축)
- 데이터 복제, ISR(In-Sync Replica) 개념과 장애 처리 메커니즘 이해
- Kafka 모니터링 도구 (Prometheus, Grafana, Kafka Manager) 사용법 익히기
- Consumer Offset 관리 (자동 커밋 vs 수동 커밋) 이해 및 활용
- 데이터 손실 및 중복 처리 대응 전략 (Idempotent Producer, Exactly Once Semantics)
- Kafka Security (SSL/TLS, SASL, ACL) 기초 설정

---

## 4단계: Kafka 생태계 도구와 실무 활용 (중급~고급)
- Kafka Connect: 데이터 소스/싱크와 Kafka 연동 자동화
- Schema Registry: 메시지 스키마 관리 및 호환성 유지
- Kafka Streams: 실시간 스트림 처리 애플리케이션 개발
- MirrorMaker: 다중 클러스터 간 데이터 복제
- 배치/스트림 처리 연동 (Spark Streaming, Flink 등)
- Kafka 클러스터 튜닝 및 성능 최적화 (batch size, linger.ms, compression 등)

---

## 5단계: 실전 프로젝트 및 고급 주제 (고급)
- Kafka 기반 이벤트 드리븐 아키텍처 설계
- 트래픽 폭증 대응 및 용량 계획
- 장애 복구 및 데이터 백업 전략 수립
- Exactly Once Processing(EOS) 심층 이해 및 구현
- 대규모 클러스터 운영 경험 쌓기
- 클라우드 Kafka 서비스 (AWS MSK, Confluent Cloud) 활용
