# Lambda의 사용 목적

본 실습에서는 **S3**의 `datalab-public-bucket` 버킷에 위치한 `lambda/` 하위의 모든 경로에서  
**CSV 파일이 업로드**될 경우 해당 **Event**를 Catch하여 **Lambda Logic**을 수행시켜 **데이터 전처리**를 진행합니다.

---

## Lambda 서비스
- **이름**: `datalab_test`

---

## Lambda 소스코드

```python
import json
import urllib.parse
import boto3
import csv
import io


s3 = boto3.client('s3')
kinesis = boto3.client(
    'kinesis',
    region_name='ap-northeast-2',
    aws_access_key_id='your-key', 
    aws_secret_access_key='your-secret-key'
)


def lambda_handler(event, context):
    try:
        records = event.get('Records', [])
        if not records:
            return {'statusCode': 400, 'body': 'No S3 records found'}

        s3_record = records[0]['s3']
        bucket = s3_record['bucket']['name']
        key = urllib.parse.unquote_plus(s3_record['object']['key'])

        # S3에서 파일 객체 읽기
        s3_obj = s3.get_object(Bucket=bucket, Key=key)
        file_content = s3_obj['Body'].read().decode('cp949')

        # CSV 읽기
        csv_reader = csv.DictReader(io.StringIO(file_content))
        rows = [row for row in csv_reader]

        # Kinesis에 전송 (각 row를 개별 메시지로 보냄)
        for row in rows:
            Data=str(row).encode('utf-8')
            kinesis.put_record(
                StreamName='stream_based_on_code',
                Data=Data,
                PartitionKey='csv-partition'
            )

        return {
            'statusCode': 200,
            'body': json.dumps({'message': 'CSV processed and sent to Kinesis', 'fileName': key})
        }

    except Exception as e:
        kinesis.put_record(
                StreamName='stream_based_on_code',
                Data=json.dumps({'error': str(e)}).encode('utf-8'),
                PartitionKey='csv-partition'
            )
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)})
        }


```
