# Kafka 운영 및 내결함성 이해

## 1. Kafka 클러스터 구성 및 Broker 확장
### 1.1 멀티 브로커 클러스터 구축
1. Kafka 압축 해제 후 동일 서버/다른 서버에 여러 개 설치 or 설정 파일 복사
2. `server.properties` 수정 (브로커마다 고유 값 필요)

```properties
broker.id=0              # 각 브로커는 유일한 ID
listeners=PLAINTEXT://localhost:9092
log.dirs=/tmp/kafka-logs-0
broker.id=1
listeners=PLAINTEXT://localhost:9093
log.dirs=/tmp/kafka-logs-1

```
3. 각각의 브로커 실행
```bash
bin/kafka-server-start.sh config/server-0.properties
bin/kafka-server-start.sh config/server-1.properties
```

---

## 2. 데이터 복제 & ISR(In-Sync Replica)
### 2.1 개념
- Replication Factor: 동일 데이터를 여러 브로커에 복제
- Leader: 읽기/쓰기를 담당하는 브로커
- Follower: Leader 데이터를 복제만 함
- ISR (In-Sync Replica): Leader와 데이터가 동기화된 브로커 목록

### 2.2 토픽 생성 시 복제
```bash
bin/kafka-topics.sh --create \
  --topic my-topic \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 2
```

### 2.3 장애 처리
- Leader 장애 시 ISR 중 하나가 Leader로 승격
- ISR 외 브로커는 데이터 불일치로 승격 불가

---

## 3. Kafka 모니터링 도구
### 3.1 Prometheus + Grafana
- Kafka JMX Exporter 사용 → Prometheus로 메트릭 수집 → Grafana 시각화
```bash
# JMX Exporter 실행 예시
KAFKA_OPTS="-javaagent:/path/jmx_prometheus_javaagent-0.16.1.jar=7071:/path/kafka-2_0_0.yml" \
bin/kafka-server-start.sh config/server.properties
```
- 주요 모니터링 지표:
    - kafka_server_BrokerTopicMetrics_MessagesInPerSec
    - kafka_server_ReplicaManager_UnderReplicatedPartitions
### 3.2 Kafka Manager
- 웹 UI로 토픽, 브로커 상태, 컨슈머 그룹 관리 가능

---
## 4. Consumer Offset 관리
### 4.1 자동 커밋 (기본)
```properties
enable.auto.commit=true
auto.commit.interval.ms=5000
```
- 장점: 간단함
- 단점: 중복/유실 가능성 있음 (프로세스 중단 시 커밋 시점 이전 메시지 재처리 가능)

### 4.2 수동 커밋
```python
consumer = KafkaConsumer('topic',
    bootstrap_servers='localhost:9092',
    enable_auto_commit=False,
    group_id='my-group'
)
for msg in consumer:
    process(msg)
    consumer.commit()
```
- 장점: 처리 완료 후 커밋 → 데이터 안정성↑
- 단점: 코드 복잡도↑

---

## 5. 데이터 손실 및 중복 처리 대응 전략
### 5.1 Idempotent Producer
동일 메시지가 여러 번 전송돼도 한 번만 저장

```python
producer = KafkaProducer(
    bootstrap_servers='localhost:9092',
    acks='all',
    enable_idempotence=True # 중복처리
)
```

### 5.2 Exactly Once Semantics (EOS)
- Producer → Kafka → Consumer → Sink까지 정확히 한 번 처리 보장
- 요구 사항:
    - enable.idempotence=true
    - transactional.id 설정
    - Consumer도 isolation.level=read_committed 사용

---

## 6. Kafka Security 기초
### 6.1 SSL/TLS 암호화
- 키스토어/트러스트스토어 생성 (keytool 사용)
- server.properties 설정
```properties
listeners=SSL://:9093
ssl.keystore.location=/path/server.keystore.jks
ssl.keystore.password=****
ssl.truststore.location=/path/server.truststore.jks
ssl.truststore.password=****
ssl.client.auth=required
```

### 6.2 SASL 인증
- 지원 방식: PLAIN, SCRAM, GSSAPI(Kerberos) 등
```properties
listeners=SASL_PLAINTEXT://:9094
sasl.enabled.mechanisms=SCRAM-SHA-256
```

### 6.3 ACL(Access Control List)

# user1에게 topic1 읽기 권한 부여
```bash
bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 \
  --add --allow-principal User:user1 --operation Read --topic topic1
```


